services:
  backend:
    build:
      context: .
      dockerfile: ./docker/backend/Dockerfile
    container_name: smarteatai_backend
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
    env_file:
      - .env
    depends_on:
      - db

  frontend:
    build:
      context: .
      dockerfile: ./docker/frontend/Dockerfile
    container_name: smarteatai_frontend
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - /app/.next
    environment:
      - NODE_ENV=development
      - CHOKIDAR_USEPOLLING=true

  db:
    image: postgres:15 # cambiar si se usa otra base de datos
    container_name: smarteatai_db
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  adminer: # Herramienta de administraci√≥n de bases de datos (navegador)
    image: adminer
    container_name: smarteatai_adminer
    ports:
      - "8080:8080"
    depends_on:
      - db
    environment:
      ADMINER_DEFAULT_SERVER: db

  ollama:
    image: ollama/ollama:latest
    container_name: smarteatai_ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

    # Este deploy solo en caso de tener/querer usar GPU NVIDIA
    deploy:
     resources:
       reservations:
         devices:
           - driver: nvidia
             count: 1
             capabilities: [gpu]
    entrypoint: /bin/bash
    command: -c "ollama pull llama3.1 || echo 'Pull failed, continue'; ollama serve --port 11434"
volumes:
  postgres_data:
  ollama_data: