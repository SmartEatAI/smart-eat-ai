#!/bin/bash
# Script para inicializar Ollama con el modelo necesario
# Ejecutar despuÃ©s de levantar los contenedores

echo "ğŸš€ Inicializando Ollama..."

# Verificar que el contenedor estÃ¡ corriendo
if ! docker ps | grep -q smarteatai_ollama; then
    echo "âŒ El contenedor de Ollama no estÃ¡ corriendo"
    echo "Ejecuta primero: docker-compose up -d"
    exit 1
fi

echo "âœ… Contenedor Ollama encontrado"

# Descargar modelo Mistral
echo "ğŸ“¥ Descargando modelo Mistral (puede tardar varios minutos)..."
docker exec smarteatai_ollama ollama pull mistral

if [ $? -eq 0 ]; then
    echo "âœ… Modelo Mistral descargado exitosamente"
    
    # Verificar modelos instalados
    echo ""
    echo "ğŸ“‹ Modelos disponibles:"
    docker exec smarteatai_ollama ollama list
    
    # Prueba rÃ¡pida
    echo ""
    echo "ğŸ§ª Probando modelo..."
    docker exec smarteatai_ollama ollama run mistral "Hola, responde brevemente: Â¿estÃ¡s funcionando?"
    
    echo ""
    echo "âœ¨ Ollama inicializado correctamente"
    echo "Puedes usar el modelo 'mistral' en el backend"
else
    echo "âŒ Error descargando modelo"
    exit 1
fi
