# Script para inicializar Ollama con el modelo necesario
# Ejecutar despuÃ©s de levantar los contenedores

Write-Host "ğŸš€ Inicializando Ollama..." -ForegroundColor Cyan

# Verificar que el contenedor estÃ¡ corriendo
$ollamaRunning = docker ps --filter "name=smarteatai_ollama" --format "{{.Names}}"

if (-not $ollamaRunning) {
    Write-Host "âŒ El contenedor de Ollama no estÃ¡ corriendo" -ForegroundColor Red
    Write-Host "Ejecuta primero: docker-compose up -d"
    exit 1
}

Write-Host "âœ… Contenedor Ollama encontrado" -ForegroundColor Green

# Descargar modelo Mistral
Write-Host "ğŸ“¥ Descargando modelo Mistral (puede tardar varios minutos)..." -ForegroundColor Yellow
docker exec smarteatai_ollama ollama pull mistral

if ($LASTEXITCODE -eq 0) {
    Write-Host "âœ… Modelo Mistral descargado exitosamente" -ForegroundColor Green
    
    # Verificar modelos instalados
    Write-Host ""
    Write-Host "ğŸ“‹ Modelos disponibles:" -ForegroundColor Cyan
    docker exec smarteatai_ollama ollama list
    
    # Prueba rÃ¡pida
    Write-Host ""
    Write-Host "ğŸ§ª Probando modelo..." -ForegroundColor Cyan
    docker exec smarteatai_ollama ollama run mistral "Hola, responde brevemente: Â¿estÃ¡s funcionando?"
    
    Write-Host ""
    Write-Host "âœ¨ Ollama inicializado correctamente" -ForegroundColor Green
    Write-Host "Puedes usar el modelo 'mistral' en el backend" -ForegroundColor Green
} else {
    Write-Host "âŒ Error descargando modelo" -ForegroundColor Red
    exit 1
}
